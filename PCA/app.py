# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_qxNdzF7i3SVxSGRAJtwEmHQfjgkllrd

#ML Pipeline Katmanı

**Veri Toplama =** Her veri kaynağı için data contract (shema + latency/ throughput SLO) belirleyin.

**Veri Doğrulama =**

*Feature Engineering =* En önemli adım online ve offline feature hazırlamadır.

- Online Feature : Kullanıcının yaptığı işlemi anında feature'a yansıtmak.

- Offline Feature : Büyük veri setlerinde günlük veya haftalık hesaplanır.

**Labeling & Ground truth =** Label gecikmeleri için önlemler;

- Survival Analysis : Random Survival Forest, DeepSurv
- Positive-Unlabeled Learning :
- Weak Supervision :

Model Geliştirme

Validation

CI / CD ( MLOps)

Serving & Infra

Monitoring

Retraining & Lifecycle

Governance

#FastAPI

Python kodlarını HTTP  servis haline getirmeye yarayan framework.

def ile yazılan fonksiyonları FastAPI otomatik olarak REST endpointine çevirir.

FastAPI yazılan fonksiyona dekoratör ekler. (@app.get, @app.post)

@app.get("/open")
def openfile():
    return {"msg":"Dosya açıldı"}


##UploadFile

FastAPI'nin sağladığı özel sınıf.

##File

FastAPI'de bir request parametresidir. API'ye "bu parametre dosya olacak" bilgisini verir.
"""

import pandas as pd
import numpy as np
from fastapi import FastAPI, UploadFile, File
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.decomposition import PCA
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams["figure.figsize"]= (9,6)

df = pd.read_csv("data.csv")
print("orijinal boyut: ", df.shape)
print("sütunlar:", df.columns.tolist())

#özellik seçimi

numeric_features = ["Year","Engine HP", "Engine Cylinders","highway MPG","Number of Doors", "city mpg", "MSRP", "Popularity"]
categorical_features = ["Make","Transmission Type","Driven_Wheels","Engine Fuel Type","Market Category","Model"]

#Eksik veri temizleme

for col in numeric_features:
  df[col] = df[col].fillna(df[col].median())

for col in categorical_features:
  df[col] = df[col].fillna("Unknown")

# Veri Ön işleme Pipeline

preprocess = ColumnTransformer(
    transformers= [
        ("num", StandardScaler(), numeric_features),
        ("cat",OneHotEncoder(handle_unknown="ignore"), categorical_features)
    ]
)

#PCA pipeline

pca = PCA(n_components=None, random_state=42)
pipe = Pipeline(steps=[
    ("preprocess", preprocess),
    ("pca",pca)
])
pipe.fit(df)

#FastAPI

app = FastAPI()

@app.post("/fit/")
async def fit_model(file: UploadFile=File(...)):
  df = pd.read_csv(file.file)
  for col in numeric_features:
    df[col] = df[col].fillna(df[col].median())

  for col in categorical_features:
    df[col] = df[col].fillna("Unknown")
  pipe.fit(df)
  joblib.dump(pipe,"pipeline.pkl")
  return {
      "status":"trained",
      "components":pipe.named_steps["pca"].n_components_
      }
@app.post("/transform/")
async def transform_data(file:UploadFile = File(...)):
  model = joblib.load("pipeline.pkl")
  df = pd.read_csv(file.file)
  Z = model.transform(df)
  return {"projection": Z[:,:2].tolist()}

"""- name : 'Deploy to Azue Web App'
uses : azure/webapps-deploy@v2
with:
    app-name:"my-fastapi-app"
    publish-profile:${{ secret.AZURE_WEBAPP_PUBLISH_PROFILE }}
    images: 'ghcr.io/${{ github.repository }}/my-fastapi-app:latest'
"""

evr = pipe.named_steps["pca"].explained_variance_ratio_
cumvar = np.cumsum(evr)

plt.plot(range(1,len(evr)+1), evr, marker="o", label="Explained Variance")
plt.plot(range(1,len(cumvar)+1), evr, marker="+", label="Cumulative Variance")
plt.xlabel("PCA Component")
plt.ylabel("Variance Ratio")
plt.title("Cumulative Variance Plot'ı")
plt.legend()
plt.show()

n_comp = np.searchsorted(cumvar, 0.70) + 1
print(f"%90 varyansı açıklayan bileşen sayısı: {n_comp}")

pca_final = PCA(n_components=n_comp, random_state=42)
pipe_final = Pipeline(steps=[
    ("preprocess", preprocess),
    ("pca", pca_final)
])

Z = pipe_final.fit_transform(df)

sns.scatterplot(x=Z[:,0],y=Z[:,1], hue=df["Vehicle Size"], alpha=0.6)
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Araç Boyutuna göre PC1 ve PC2")
plt.legend()
plt.show()

ohe = pipe_final.named_steps["preprocess"].named_transformers_["cat"]
cat_names = ohe.get_feature_names_out(categorical_features)
all_features = numeric_features + cat_names.tolist()

load = pd.DataFrame(
    pipe_final.named_steps["pca"].components_.T,
    index = all_features,
    columns = [f"PC{i+1}" for i in range(n_comp)]
)

print("Load tablosu")
print(load.iloc[:15,:5]) # ilk 15 özellik ve 5 PCA sütunu görünür

df["PC4"] = Z[:,3]

brands= ["Toyota", "Ford","Volkswagen","Hyundai","Ferrari","Bugatti","Aston Martin","BMW","Mercedes-Benz"]

sample_df = df[df["Make"].isin(brands)].groupby("Make")["PC4"].mean().reset_index()

plt.figure(figsize=(10,6))
sns.barplot(x="PC4", y="Make", data=sample_df, palette="coolwarm")
plt.axvline(0,color="black",linestyle= "--")
plt.title("Markaların PC4 Üzerindeki Konumu")
plt.xlabel("PC4 Skoru")
plt.ylabel("Marka")
plt.show()

sample_df